Вот строгое доказательство времени работы интерполяционного поиска, полностью переписанное с использованием LaTeX для математических формул:

**Основная Идея Доказательства**
Доказывается, что среднее число обращений к файлу для нахождения ключа $Y$ в отсортированном файле из $N$ равномерно распределенных ключей составляет $O(\log \log N)$. Доказательство основано на анализе уменьшения ожидаемой ошибки в позиции искомого ключа после каждого шага.

**Ключевые Обозначения**
1. **Состояние поиска**: $S_j = (L_j, U_j, X_{L_j}, X_{U_j})$
   - $L_j, U_j$: индексы границ текущего подфайла
   - $X_{L_j}, X_{U_j}$: значения ключей на границах (уже проверены)
   - $N_j = U_j - L_j - 1$: число непроверенных ключей

2. **Ключевые величины**:
   - $K^*$: истинный индекс искомого ключа $Y$ (случайная величина)
   - $P_j = \frac{Y - X_{L_j}}{X_{U_j} - X_{L_j}}$: вероятность случайного ключа в подфайле $\leq Y$
   - $K_j = E(K^* \mid S_j) = L_j + N_j \cdot P_j$: ожидаемая позиция $K^*$
   - $D_j$: расстояние между последовательными проверками:
     $
     D_j = 
     \begin{cases} 
     N_{j+1} \cdot P_{j+1} & \text{если } X_{K_j} < Y \\
     N_{j+1} \cdot (1 - P_{j+1}) & \text{если } X_{K_j} > Y 
     \end{cases}
     $
     Ключевое свойство: $D_j = |E(K^* - K_j \mid S_1, \dots, S_{j+1})|$

3. **Свойства условного ожидания**:
   - $E(E(X \mid Y_1,\dots,Y_j) \mid Y_1,\dots,Y_{j-1}) = E(X \mid Y_1,\dots,Y_{j-1})$
   - Для вогнутой $f$: $E(f(X) \mid Y_1,\dots,Y_j) \leq f(E(X \mid Y_1,\dots,Y_j))$

---

**Доказательство**

**Лемма 1**. Для $j > 1$:
$
E(D_j^2 \mid S_1, \dots, S_j) \leq D_{j-1}
$

*Доказательство*:
- При фиксированном $S_1,\dots,S_j$, величина $K^*$ имеет биномиальное распределение $B(N_j, P_j)$ с дисперсией $\text{Var}(K^* \mid S_1,\dots,S_j) = N_j P_j (1 - P_j)$
- Используя свойства условного ожидания:
  $
  E(D_j^2 \mid S_1,\dots,S_j) = E\left( \left[ E(K^* - K_j \mid S_1,\dots,S_{j+1}) \right]^2 \mid S_1,\dots,S_j \right)
  $
- По неравенству Йенсена для $x^2$:
  $
  \leq E\left( E\left( (K^* - K_j)^2 \mid S_1,\dots,S_{j+1} \right) \mid S_1,\dots,S_j \right) = E\left( (K^* - K_j)^2 \mid S_1,\dots,S_j \right)
  $
- Это условная дисперсия:
  $
  = \text{Var}(K^* \mid S_1,\dots,S_j) = N_j P_j (1 - P_j) \leq D_{j-1}
  $
- Для $j=1$: $E(D_1^2 \mid S_1) < \frac{N}{4}$ и $E(D_1 \mid S_1) < \frac{1}{2}\sqrt{N}$

---

**Теорема 1** (Экспоненциальное уменьшение ошибки):
$
E(D_j \mid S_1) < N^{2^{-j}}
$

*Доказательство индукцией*:
- База ($j=1$): $E(D_1 \mid S_1) < \sqrt{N} = N^{2^{-1}}$
- Шаг $j \to j+1$:
  $
  \left[ E(D_{j+1} \mid S_1) \right]^2 \leq E(D_{j+1}^2 \mid S_1) = E\left( E(D_{j+1}^2 \mid S_1,\dots,S_{j+1}) \mid S_1 \right) \leq E(D_j \mid S_1) < N^{2^{-j}}
  $
  $
  \implies E(D_{j+1} \mid S_1) < \left( N^{2^{-j}} \right)^{1/2} = N^{2^{-(j+1)}}
  $
- Интерпретация: после $j$ шагов ошибка уменьшается как $N^{1/2^j}$

---

**Теорема 2** (Главный результат):
$
E(T) < \log \log N
$
где $T$ — число шагов до достижения $D_j \leq 2$.

*Доказательство*:
1. **Построение супермартингала**:
   - Пусть $Z_j = \log D_j$
   - Из Леммы 1 и вогнутости $\log$:
     $
     E(2Z_j \mid S_1,\dots,S_j) \leq \log E(D_j^2 \mid S_1,\dots,S_j) \leq \log D_{j-1} = Z_{j-1}
     $
   - Умножая на $2^{j-1}$:
     $
     E(2^j Z_j \mid S_1,\dots,S_j) \leq 2^{j-1} Z_{j-1}
     $
   - Последовательность $W_j = 2^j Z_j$ — супермартингал

2. **Момент остановки**:
   - $T = \min \{ j : Z_j \leq 1 \}$ (первый шаг, где $D_j \leq 2$)
   - Для непрерывного случая (когда $Z_j$ "перескакивает" 1) строится интерполяция $Z(t)$

3. **Теорема об остановке**:
   $
   E(W_T) \leq E(W_1) = E(2 \log D_1) \leq \log E(D_1^2) < \log \frac{N}{4} < \log N
   $
   - Поскольку $W_T \approx 2^T \cdot 1$:
     $
     E(2^T) < \log N
     $

4. **Переход к $E(T)$**:
   - По неравенству Йенсена для выпуклой $2^x$:
     $
     2^{E(T)} \leq E(2^T) < \log N
     $
   - Логарифмируя:
     $
     E(T) < \log \log N
     $

---

**Оценки "хвостов" распределения**

1. **Вероятность отклонения** (по Чебышеву):
   $
   P\left(T \geq (1+\alpha) \log \log N\right) \leq (\log N)^{-\alpha}
   $

2. **Среднее превышение** (Теорема 3):
   $
   E\left( (T - \log \log N)_+ \right) \leq \frac{\log e}{e} \approx 0.53
   $
   где $(x)_+ = \max(x, 0)$

---

**Экспериментальное подтверждение**
- Для $N = 400\,000$ ($\log \log N \approx 4.21$):
  - Среднее число обращений: $4.28$
  - Среднее превышение: $0.481 < 0.53$
- Результаты для различных $N$:

  | $\log N$ | $N$      | $\log \log N$ | Среднее | Максимум |
  |------------|------------|-----------------|---------|----------|
  | 6          | 64         | 2.585           | 2.451   | 4        |
  | 16         | 65 536     | 4.000           | 4.019   | 9        |
  | 18         | 262 144    | 4.170           | 4.097   | 9        |

---

**Заключение**
Для отсортированного файла с равномерно распределенными ключами интерполяционный поиск имеет среднюю сложность $O(\log \log N)$. Эта оценка:
- Асимптотически точна (нижняя граница доказана Yao & Yao)
- Имеет пренебрежимо малую вероятность значительных отклонений
- Подтверждена экспериментально
- Оптимальна для данной модели данных